{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from definitions import path_join, make_directory, EXPERIMENTS_DIR, VENSIM_MODELS_DIR, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNOWN_MODEL = 'known model'\n",
    "UNKNOWN_MODEL = 'unknown model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'teacup'\n",
    "experiment_name = '{}_recovery'.format(model_name)\n",
    "\n",
    "mode = UNKNOWN_MODEL\n",
    "need_retrain = True\n",
    "seed = 123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "general_params = {\n",
    "    'phi_h': tf.keras.activations.linear,\n",
    "    'phi_o': tf.keras.activations.linear,\n",
    "}\n",
    "\n",
    "train_params = {\n",
    "    'learning_rate': 1e-1,\n",
    "    'epochs_before_decay': 0.1,\n",
    "    'epochs_count': 50,\n",
    "    'learning_rate_decay': 1/3,\n",
    "    'iterations_count': 300,\n",
    "    'early_stopping_patience': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_experiment_enviroment(model_name, experiment_name, mode):\n",
    "    experiment_settings = dict()\n",
    "    \n",
    "    experiment_settings['model_name'] = model_name\n",
    "    experiment_settings['experiment_name'] = experiment_name\n",
    "    experiment_settings['mode'] = mode\n",
    "    \n",
    "    experiment_dir = path_join(EXPERIMENTS_DIR, experiment_name)\n",
    "    make_directory(experiment_dir)\n",
    "    experiment_settings['experiment_dir'] = experiment_dir\n",
    "    \n",
    "    tf_model_dir = path_join(experiment_dir, 'tf_model')\n",
    "    make_directory(tf_model_dir)\n",
    "    experiment_settings['tf_model_dir'] = tf_model_dir\n",
    "    \n",
    "    images_dir = path_join(experiment_dir, 'images')\n",
    "    make_directory(images_dir)\n",
    "    experiment_settings['images_dir'] = images_dir\n",
    "    \n",
    "    log_path = path_join(experiment_dir, 'log.log')\n",
    "    logging.basicConfig(filename=log_path, level=logging.INFO)\n",
    "    experiment_settings['log_path'] = log_path\n",
    "\n",
    "    vensim_model_file = path_join(VENSIM_MODELS_DIR, '{}.mdl'.format(model_name))\n",
    "    experiment_settings['vensim_model_file'] = vensim_model_file\n",
    "    \n",
    "    prn_model_dir = path_join(tf_model_dir, 'prn_model')\n",
    "    nn_model_dir = path_join(tf_model_dir, 'base_nn_model')\n",
    "    make_directory(prn_model_dir)\n",
    "    make_directory(nn_model_dir)\n",
    "    experiment_settings['prn_model_dir'] = prn_model_dir\n",
    "    experiment_settings['nn_model_dir'] = nn_model_dir\n",
    "\n",
    "    return experiment_settings\n",
    "    \n",
    "experiment_settings = create_experiment_enviroment(model_name, experiment_name, mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from definitions import path_join, DATA_DIR\n",
    "\n",
    "dataset_dir = path_join(DATA_DIR, model_name)\n",
    "dataset_file = path_join(dataset_dir, 'dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(dataset_file)\n",
    "dt = 0.03125\n",
    "stopwords = ['TIME', 'sim_index']\n",
    "fields = [column for column in data.columns if column not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt: 0.03125\n"
     ]
    }
   ],
   "source": [
    "from module.fd_model.vensim_fd_converter import create_unknown_model\n",
    "\n",
    "FD = create_unknown_model(fields)\n",
    "FD.dT = dt\n",
    "\n",
    "print('dt: {}'.format(dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Characteristic Time', 'Room Temperature', 'Teacup Temperature']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = [level for level in FD.names_units_map.keys()]\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def np_preproc_for_rnn3d(numpy_array, fields):\n",
    "    x_groups = [group[1][fields].values[:-1] for group in numpy_array]\n",
    "    y_groups = [group[1][fields].values[1:] for group in numpy_array]\n",
    "    \n",
    "    train_X, valid_X, train_y, valid_y = train_test_split(x_groups, y_groups, test_size=0.2, random_state=seed)\n",
    "    \n",
    "    train_X = np.concatenate(train_X, axis=0)\n",
    "    valid_X = np.concatenate(valid_X, axis=0)\n",
    "    \n",
    "    train_y = np.concatenate(train_y, axis=0)\n",
    "    valid_y = np.concatenate(valid_y, axis=0)\n",
    "\n",
    "    return (train_X, train_y), (valid_X, valid_y)\n",
    "\n",
    "\n",
    "def generate_train_data(df, fields):\n",
    "    dataset = df[fields].values\n",
    "    grouped = df.groupby(['sim_index'])[fields]\n",
    "    \n",
    "    return dataset, np_preproc_for_rnn3d(grouped, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (prn_train, prn_valid) = generate_train_data(data, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prn_train_X, prn_train_y = prn_train\n",
    "prn_valid_X, prn_valid_y = prn_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prn_train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch.base_nn import BaseNN\n",
    "\n",
    "predictor = BaseNN(prn_train_X.shape[1], prn_train_X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12000 samples, validate on 3000 samples\n",
      "Epoch 1/50\n",
      "12000/12000 [==============================] - 1s 98us/sample - loss: 2026.9577 - mse: 2026.9585 - val_loss: 1113.9975 - val_mse: 1113.9972\n",
      "Epoch 2/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 851.8382 - mse: 851.8379 - val_loss: 561.0353 - val_mse: 561.0352\n",
      "Epoch 3/50\n",
      "12000/12000 [==============================] - 1s 66us/sample - loss: 460.5712 - mse: 460.5715 - val_loss: 308.6769 - val_mse: 308.6770\n",
      "Epoch 4/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 248.0350 - mse: 248.0351 - val_loss: 161.2519 - val_mse: 161.2519\n",
      "Epoch 5/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 124.3901 - mse: 124.3901 - val_loss: 78.2769 - val_mse: 78.2769\n",
      "Epoch 6/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 57.5635 - mse: 57.5635 - val_loss: 34.9408 - val_mse: 34.9408\n",
      "Epoch 7/50\n",
      "12000/12000 [==============================] - 1s 64us/sample - loss: 24.5706 - mse: 24.5706 - val_loss: 14.7602 - val_mse: 14.7602\n",
      "Epoch 8/50\n",
      "12000/12000 [==============================] - 1s 64us/sample - loss: 10.1219 - mse: 10.1219 - val_loss: 6.4113 - val_mse: 6.4113\n",
      "Epoch 9/50\n",
      "12000/12000 [==============================] - 1s 68us/sample - loss: 4.5255 - mse: 4.5255 - val_loss: 3.2746 - val_mse: 3.2746\n",
      "Epoch 10/50\n",
      "12000/12000 [==============================] - 1s 63us/sample - loss: 2.4633 - mse: 2.4633 - val_loss: 1.9837 - val_mse: 1.9837\n",
      "Epoch 11/50\n",
      "12000/12000 [==============================] - 1s 63us/sample - loss: 1.5567 - mse: 1.5567 - val_loss: 1.2863 - val_mse: 1.2863\n",
      "Epoch 12/50\n",
      "12000/12000 [==============================] - 1s 64us/sample - loss: 1.0057 - mse: 1.0057 - val_loss: 0.8104 - val_mse: 0.8104\n",
      "Epoch 13/50\n",
      "12000/12000 [==============================] - 1s 64us/sample - loss: 0.6158 - mse: 0.6158 - val_loss: 0.4744 - val_mse: 0.4744\n",
      "Epoch 14/50\n",
      "12000/12000 [==============================] - 1s 64us/sample - loss: 0.3463 - mse: 0.3463 - val_loss: 0.2540 - val_mse: 0.2540\n",
      "Epoch 15/50\n",
      "12000/12000 [==============================] - 1s 64us/sample - loss: 0.1752 - mse: 0.1752 - val_loss: 0.1195 - val_mse: 0.1195\n",
      "Epoch 16/50\n",
      "12000/12000 [==============================] - 1s 66us/sample - loss: 0.0779 - mse: 0.0779 - val_loss: 0.0486 - val_mse: 0.0486\n",
      "Epoch 17/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 0.0295 - mse: 0.0295 - val_loss: 0.0165 - val_mse: 0.0165\n",
      "Epoch 18/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 19/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 0.0023 - mse: 0.0023 - val_loss: 9.4321e-04 - val_mse: 9.4321e-04\n",
      "Epoch 20/50\n",
      "12000/12000 [==============================] - 1s 64us/sample - loss: 4.2232e-04 - mse: 4.2232e-04 - val_loss: 1.4352e-04 - val_mse: 1.4352e-04\n",
      "Epoch 21/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 5.9829e-05 - mse: 5.9829e-05 - val_loss: 1.9055e-05 - val_mse: 1.9055e-05\n",
      "Epoch 22/50\n",
      "12000/12000 [==============================] - 1s 66us/sample - loss: 1.0056e-05 - mse: 1.0056e-05 - val_loss: 6.1835e-06 - val_mse: 6.1835e-06\n",
      "Epoch 23/50\n",
      "12000/12000 [==============================] - 1s 70us/sample - loss: 5.5697e-06 - mse: 5.5697e-06 - val_loss: 5.3370e-06 - val_mse: 5.3370e-06\n",
      "Epoch 24/50\n",
      "12000/12000 [==============================] - 1s 68us/sample - loss: 5.3341e-06 - mse: 5.3341e-06 - val_loss: 5.3500e-06 - val_mse: 5.3500e-06\n",
      "Epoch 25/50\n",
      "12000/12000 [==============================] - 1s 64us/sample - loss: 5.3496e-06 - mse: 5.3496e-06 - val_loss: 5.3529e-06 - val_mse: 5.3529e-06\n",
      "Epoch 26/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 5.3852e-06 - mse: 5.3852e-06 - val_loss: 5.3595e-06 - val_mse: 5.3595e-06\n",
      "Epoch 27/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 5.3520e-06 - mse: 5.3520e-06 - val_loss: 5.3842e-06 - val_mse: 5.3842e-06\n",
      "Epoch 28/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 5.3657e-06 - mse: 5.3657e-06 - val_loss: 5.3092e-06 - val_mse: 5.3092e-06\n",
      "Epoch 29/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 5.4005e-06 - mse: 5.4005e-06 - val_loss: 5.3394e-06 - val_mse: 5.3394e-06\n",
      "Epoch 30/50\n",
      "12000/12000 [==============================] - 1s 66us/sample - loss: 5.4900e-06 - mse: 5.4900e-06 - val_loss: 5.4113e-06 - val_mse: 5.4113e-06\n",
      "Epoch 31/50\n",
      "12000/12000 [==============================] - 1s 65us/sample - loss: 5.4374e-06 - mse: 5.4374e-06 - val_loss: 5.3143e-06 - val_mse: 5.3143e-06\n",
      "Epoch 32/50\n",
      "12000/12000 [==============================] - 1s 64us/sample - loss: 5.4703e-06 - mse: 5.4703e-06 - val_loss: 5.5070e-06 - val_mse: 5.5070e-06\n",
      "Epoch 33/50\n",
      "12000/12000 [==============================] - 1s 68us/sample - loss: 5.5133e-06 - mse: 5.5133e-06 - val_loss: 5.4025e-06 - val_mse: 5.4025e-06\n"
     ]
    }
   ],
   "source": [
    "if need_retrain:\n",
    "    predictor.train(prn_train_X, prn_train_y, (prn_valid_X, prn_valid_y), train_params, experiment_settings['nn_model_dir'])\n",
    "    pass\n",
    "nn_output = predictor.test(prn_valid_X, experiment_settings['nn_model_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.000001, 69.99999 , 40.375206],\n",
       "       [10.000001, 69.99999 , 40.750454],\n",
       "       [10.000001, 69.99999 , 41.11583 ],\n",
       "       [10.000001, 69.99999 , 41.47133 ],\n",
       "       [10.000001, 69.99999 , 41.826828]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_output[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.calculate_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(required_columns_data, output):\n",
    "    output = np.array(output)\n",
    "    error = sum(abs((output-required_columns_data)/required_columns_data))/required_columns_data.shape[0]\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train set error</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_simulation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-694b8cbc6614>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minitial_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprn_train_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprn_train_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0miterations_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprn_train_X\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_prn_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_simulation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprn_model_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_prn_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_prn_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_prn_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'run_simulation' is not defined"
     ]
    }
   ],
   "source": [
    "initial_value = np.reshape(prn_train_X[0], [1, prn_train_y.shape[1]])\n",
    "iterations_count = prn_train_X.shape[0]-1\n",
    "train_prn_output = run_simulation(rnn_model, prn_model_dir, initial_value, iterations_count)\n",
    "train_prn_error = calculate_error(train_y, train_prn_output)\n",
    "train_prn_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01026829, 0.2333064 , 0.00324267])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_nn_output = predictor.test(train_X, nn_model_dir)\n",
    "train_nn_error = calculate_error(train_y, train_nn_output)\n",
    "train_nn_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Test set error</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (384,6) (77,6) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-47eed2a4209e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprn_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprn_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprn_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-38-6eebf2a3f31c>\u001b[0m in \u001b[0;36mcalculate_error\u001b[1;34m(required_columns_data, output)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequired_columns_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0merror\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mrequired_columns_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mrequired_columns_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mrequired_columns_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (384,6) (77,6) "
     ]
    }
   ],
   "source": [
    "predictor.test(train_X, nn_model_dir)\n",
    "prn_error = calculate_error(valid_y, prn_output)\n",
    "prn_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01008007, 0.23619833, 0.00327633])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_nn_output = predictor.test(valid_X, nn_model_dir)\n",
    "valid_nn_error = calculate_error(valid_y, valid_nn_output)\n",
    "valid_nn_error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
